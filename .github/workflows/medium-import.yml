name: Import Medium Posts and Build Hugo

on:
  schedule:
    # 毎週日曜日 21:00 (UTC) = 日本時間 06:00 (月曜日)
    # 日本時間の日曜日 21:00 にするには 12:00 (UTC) を指定
    - cron: '0 12 * * 0'
  workflow_dispatch: # 手動実行も可能

env:
  HUGO_VERSION: '0.128.0'

jobs:
  import-and-build:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pages: write
      id-token: write

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'

    - name: Setup Hugo
      uses: peaceiris/actions-hugo@v2
      with:
        hugo-version: ${{ env.HUGO_VERSION }}
        extended: true

    - name: Install medium-2-md
      run: |
        npm install -g medium-2-md
        npm install -g medium-to-markdown

    - name: Setup Python for custom scripts
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install Python dependencies
      run: |
        pip install feedparser requests beautifulsoup4 markdownify python-dateutil

    - name: Create Medium fetcher script
      run: |
        cat > fetch_medium_posts.py << 'EOF'
        #!/usr/bin/env python3
        import feedparser
        import requests
        import os
        import json
        from datetime import datetime, timedelta
        from bs4 import BeautifulSoup
        from markdownify import markdownify as md
        import re
        from urllib.parse import urlparse

        def fetch_recent_posts(username="hiro", days_back=7):
            """Mediumから最近の記事を取得"""
            feed_url = f"https://medium.com/feed/@{username}"
            
            try:
                print(f"Fetching feed from: {feed_url}")
                feed = feedparser.parse(feed_url)
                
                if not feed.entries:
                    print("No posts found in feed")
                    return []
                
                recent_posts = []
                cutoff_date = datetime.now() - timedelta(days=days_back)
                
                for entry in feed.entries:
                    # 投稿日時をチェック
                    post_date = datetime(*entry.published_parsed[:6])
                    
                    if post_date > cutoff_date:
                        recent_posts.append({
                            'title': entry.title,
                            'link': entry.link,
                            'published': post_date.isoformat(),
                            'summary': entry.summary,
                            'content': entry.get('content', [{}])[0].get('value', ''),
                            'guid': entry.guid
                        })
                        print(f"Found recent post: {entry.title}")
                
                return recent_posts
                
            except Exception as e:
                print(f"Error fetching feed: {e}")
                return []

        def clean_medium_content(html_content):
            """MediumのHTMLコンテンツをクリーンアップ"""
            if not html_content:
                return ""
            
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # 不要な要素を削除
            for element in soup.find_all(['script', 'style', 'noscript']):
                element.decompose()
            
            # MediumのFigureキャプションを処理
            for figure in soup.find_all('figure'):
                figcaption = figure.find('figcaption')
                if figcaption:
                    figcaption.name = 'p'
                    figcaption['class'] = 'caption'
            
            # HTMLをMarkdownに変換
            markdown_content = md(str(soup), heading_style="ATX")
            
            # 不要な空行を削除
            markdown_content = re.sub(r'\n\s*\n\s*\n', '\n\n', markdown_content)
            
            return markdown_content.strip()

        def generate_slug(title):
            """タイトルからslugを生成"""
            # 日本語の場合はURLエンコード
            import urllib.parse
            slug = urllib.parse.quote(title.lower(), safe='')
            return slug[:100]  # 長すぎる場合は切り詰め

        def create_hugo_post(post, output_dir):
            """Hugo用の記事ファイルを作成"""
            try:
                title = post['title']
                slug = generate_slug(title)
                date = post['published']
                content = clean_medium_content(post['content'])
                
                # Page Bundle用のディレクトリ作成
                post_dir = os.path.join(output_dir, f"medium-{slug}")
                os.makedirs(post_dir, exist_ok=True)
                
                # Front matterを作成
                frontmatter = f"""---
title: "{title}"
date: "{date}"
slug: "{slug}"
source: "medium"
original_url: "{post['link']}"
draft: false
---

"""
                
                # index.mdファイルを作成
                with open(os.path.join(post_dir, 'index.md'), 'w', encoding='utf-8') as f:
                    f.write(frontmatter + content)
                
                print(f"Created post: {post_dir}/index.md")
                return True
                
            except Exception as e:
                print(f"Error creating post for '{post['title']}': {e}")
                return False

        def main():
            print("=== Medium Post Fetcher ===")
            
            # 設定
            username = "hiro"
            days_back = 7
            output_dir = "content/posts"
            
            # 出力ディレクトリを作成
            os.makedirs(output_dir, exist_ok=True)
            
            # 最近の記事を取得
            posts = fetch_recent_posts(username, days_back)
            
            if not posts:
                print("No recent posts found")
                return
            
            print(f"Found {len(posts)} recent posts")
            
            # 各記事をHugo形式で保存
            success_count = 0
            for post in posts:
                if create_hugo_post(post, output_dir):
                    success_count += 1
            
            print(f"Successfully imported {success_count}/{len(posts)} posts")
            
            # サマリーファイルを作成
            summary = {
                'import_date': datetime.now().isoformat(),
                'posts_found': len(posts),
                'posts_imported': success_count,
                'posts': [{'title': p['title'], 'url': p['link']} for p in posts]
            }
            
            with open('medium_import_summary.json', 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2)

        if __name__ == '__main__':
            main()
        EOF

    - name: Fetch new Medium posts
      run: |
        python fetch_medium_posts.py

    - name: Check for new posts
      id: check_posts
      run: |
        if [ -f "medium_import_summary.json" ]; then
          POSTS_COUNT=$(jq '.posts_imported' medium_import_summary.json)
          echo "posts_count=$POSTS_COUNT" >> $GITHUB_OUTPUT
          
          if [ "$POSTS_COUNT" -gt 0 ]; then
            echo "has_new_posts=true" >> $GITHUB_OUTPUT
            echo "Found $POSTS_COUNT new posts"
          else
            echo "has_new_posts=false" >> $GITHUB_OUTPUT
            echo "No new posts found"
          fi
        else
          echo "has_new_posts=false" >> $GITHUB_OUTPUT
          echo "No import summary found"
        fi

    - name: Install Ruby and dependencies (for post processing)
      if: steps.check_posts.outputs.has_new_posts == 'true'
      uses: ruby/setup-ruby@v1
      with:
        ruby-version: '3.2'
        bundler-cache: false

    - name: Process new posts (Page Bundle conversion)
      if: steps.check_posts.outputs.has_new_posts == 'true'
      run: |
        # 必要に応じて既存のRubyスクリプトを実行
        # ruby convert_to_page_bundles.rb
        echo "Post processing completed"

    - name: Build Hugo site
      if: steps.check_posts.outputs.has_new_posts == 'true'
      run: |
        hugo --minify --gc

    - name: Setup Pages
      if: steps.check_posts.outputs.has_new_posts == 'true'
      uses: actions/configure-pages@v4

    - name: Upload Pages artifact
      if: steps.check_posts.outputs.has_new_posts == 'true'
      uses: actions/upload-pages-artifact@v3
      with:
        path: ./public

    - name: Deploy to GitHub Pages
      if: steps.check_posts.outputs.has_new_posts == 'true'
      id: deployment
      uses: actions/deploy-pages@v4

    - name: Commit new posts
      if: steps.check_posts.outputs.has_new_posts == 'true'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        git add content/posts/medium-*
        git add medium_import_summary.json
        
        if ! git diff --cached --quiet; then
          POSTS_COUNT=$(jq '.posts_imported' medium_import_summary.json)
          git commit -m "Add $POSTS_COUNT new posts from Medium"
          git push
        else
          echo "No changes to commit"
        fi

    - name: Create summary comment
      if: steps.check_posts.outputs.has_new_posts == 'true'
      run: |
        echo "## 📝 Medium記事インポート完了" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "インポート日時: $(date)" >> $GITHUB_STEP_SUMMARY
        echo "新規記事数: $(jq '.posts_imported' medium_import_summary.json)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### インポートされた記事:" >> $GITHUB_STEP_SUMMARY
        jq -r '.posts[] | "- [\(.title)](\(.url))"' medium_import_summary.json >> $GITHUB_STEP_SUMMARY

    - name: No new posts message
      if: steps.check_posts.outputs.has_new_posts == 'false'
      run: |
        echo "## 📝 Medium記事チェック完了" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "新しい記事は見つかりませんでした。" >> $GITHUB_STEP_SUMMARY
        echo "チェック日時: $(date)" >> $GITHUB_STEP_SUMMARY