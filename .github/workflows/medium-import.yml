name: Import Medium Posts and Build Hugo

on:
  schedule:
    - cron: "0 12 * * 0"
  workflow_dispatch:

env:
  HUGO_VERSION: "0.128.0"

jobs:
  import-and-build:
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "18"

      - name: Setup Hugo
        uses: peaceiris/actions-hugo@v2
        with:
          hugo-version: ${{ env.HUGO_VERSION }}
          extended: true

      - name: Setup Python for custom scripts
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install Python dependencies
        run: |
          pip install feedparser requests beautifulsoup4 markdownify python-dateutil

      - name: Create scripts directory and fetcher script
        run: |
          mkdir -p scripts/logs
          cat > scripts/fetch_medium_posts.py << 'PYTHON_EOF'
          #!/usr/bin/env python3
          import feedparser
          import requests
          import os
          import json
          import uuid
          from datetime import datetime, timedelta
          from bs4 import BeautifulSoup
          from markdownify import markdownify as md
          import re
          from urllib.parse import urlparse

          def fetch_recent_posts(username="hiro", days_back=7):
              """Mediumã‹ã‚‰æœ€è¿‘ã®è¨˜äº‹ã‚’å–å¾—"""
              feed_url = f"https://medium.com/feed/@{username}"
              
              try:
                  print(f"Fetching feed from: {feed_url}")
                  feed = feedparser.parse(feed_url)
                  
                  if not feed.entries:
                      print("No posts found in feed")
                      return []
                  
                  recent_posts = []
                  cutoff_date = datetime.now() - timedelta(days=days_back)
                  
                  for entry in feed.entries:
                      post_date = datetime(*entry.published_parsed[:6])
                      
                      if post_date > cutoff_date:
                          recent_posts.append({
                              'title': entry.title,
                              'link': entry.link,
                              'published': post_date.isoformat(),
                              'summary': entry.summary,
                              'content': entry.get('content', [{}])[0].get('value', ''),
                              'guid': entry.guid
                          })
                          print(f"Found recent post: {entry.title}")
                  
                  return recent_posts
                  
              except Exception as e:
                  print(f"Error fetching feed: {e}")
                  return []

          def clean_medium_content(html_content):
              """Mediumã®HTMLã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
              if not html_content:
                  return ""
              
              soup = BeautifulSoup(html_content, 'html.parser')
              
              for element in soup.find_all(['script', 'style', 'noscript']):
                  element.decompose()
              
              for figure in soup.find_all('figure'):
                  figcaption = figure.find('figcaption')
                  if figcaption:
                      figcaption.name = 'p'
                      figcaption['class'] = 'caption'
              
              markdown_content = md(str(soup), heading_style="ATX")
              markdown_content = re.sub(r'\n\s*\n\s*\n', '\n\n', markdown_content)
              
              return markdown_content.strip()

          def generate_uuid_slug():
              """UUIDãƒ™ãƒ¼ã‚¹ã®slugã‚’ç”Ÿæˆ"""
              return str(uuid.uuid4())

          def create_hugo_post(post, output_dir):
              """Hugoç”¨ã®è¨˜äº‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
              try:
                  title = post['title']
                  uuid_slug = generate_uuid_slug()
                  date = post['published']
                  content = clean_medium_content(post['content'])
                  
                  post_dir = os.path.join(output_dir, f"medium-{uuid_slug}")
                  os.makedirs(post_dir, exist_ok=True)
                  
                  # Front matterã‚’æ–‡å­—åˆ—ã§ä½œæˆï¼ˆYAMLã‚¨ãƒ©ãƒ¼å›žé¿ï¼‰
                  frontmatter = '---\n'
                  frontmatter += f'title: "{title}"\n'
                  frontmatter += f'date: "{date}"\n'
                  frontmatter += f'slug: "{uuid_slug}"\n'
                  frontmatter += 'source: "medium"\n'
                  frontmatter += f'original_url: "{post["link"]}"\n'
                  frontmatter += f'uuid: "{uuid_slug}"\n'
                  frontmatter += 'draft: false\n'
                  frontmatter += '---\n\n'
                  
                  with open(os.path.join(post_dir, 'index.md'), 'w', encoding='utf-8') as f:
                      f.write(frontmatter + content)
                  
                  print(f"Created post: {post_dir}/index.md with UUID: {uuid_slug}")
                  return True, uuid_slug
                  
              except Exception as e:
                  print(f"Error creating post for '{post['title']}': {e}")
                  return False, None

          def main():
              print("=== Medium Post Fetcher (UUIDç‰ˆ) ===")
              
              username = "hiro"
              days_back = 7
              output_dir = "content/posts"
              
              os.makedirs(output_dir, exist_ok=True)
              
              posts = fetch_recent_posts(username, days_back)
              
              if not posts:
                  print("No recent posts found")
                  return
              
              print(f"Found {len(posts)} recent posts")
              
              success_count = 0
              imported_posts = []
              
              for post in posts:
                  success, uuid_slug = create_hugo_post(post, output_dir)
                  if success:
                      success_count += 1
                      imported_posts.append({
                          'title': post['title'],
                          'url': post['link'],
                          'uuid': uuid_slug
                      })
              
              print(f"Successfully imported {success_count}/{len(posts)} posts")
              
              summary = {
                  'import_date': datetime.now().isoformat(),
                  'posts_found': len(posts),
                  'posts_imported': success_count,
                  'posts': imported_posts
              }
              
              # scripts/logsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜
              with open('scripts/logs/medium_import_summary.json', 'w', encoding='utf-8') as f:
                  json.dump(summary, f, ensure_ascii=False, indent=2)

          if __name__ == '__main__':
              main()
          PYTHON_EOF

      - name: Fetch new Medium posts
        run: |
          python scripts/fetch_medium_posts.py

      - name: Check for new posts
        id: check_posts
        run: |
          if [ -f "scripts/logs/medium_import_summary.json" ]; then
            POSTS_COUNT=$(jq '.posts_imported' scripts/logs/medium_import_summary.json)
            echo "posts_count=$POSTS_COUNT" >> $GITHUB_OUTPUT
            
            if [ "$POSTS_COUNT" -gt 0 ]; then
              echo "has_new_posts=true" >> $GITHUB_OUTPUT
              echo "Found $POSTS_COUNT new posts"
            else
              echo "has_new_posts=false" >> $GITHUB_OUTPUT
              echo "No new posts found"
            fi
          else
            echo "has_new_posts=false" >> $GITHUB_OUTPUT
            echo "No import summary found"
          fi

      - name: Build Hugo site
        if: steps.check_posts.outputs.has_new_posts == 'true'
        run: |
          hugo --minify --gc
          echo "Hugo build completed successfully"

      - name: Commit new posts
        if: steps.check_posts.outputs.has_new_posts == 'true'
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"

          git add content/posts/medium-*
          git add scripts/logs/medium_import_summary.json

          if ! git diff --cached --quiet; then
            POSTS_COUNT=$(jq '.posts_imported' scripts/logs/medium_import_summary.json)
            git commit -m "Add $POSTS_COUNT new posts from Medium (UUIDç‰ˆ)"
            git push
          else
            echo "No changes to commit"
          fi

      - name: Create summary comment
        if: steps.check_posts.outputs.has_new_posts == 'true'
        run: |
          echo "## ðŸ“ Mediumè¨˜äº‹ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº† (UUIDç‰ˆ)" >> $GITHUB_STEP_SUMMARY
          echo "ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ—¥æ™‚: $(date)" >> $GITHUB_STEP_SUMMARY
          echo "æ–°è¦è¨˜äº‹æ•°: $(jq '.posts_imported' scripts/logs/medium_import_summary.json)" >> $GITHUB_STEP_SUMMARY
          echo "### ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ãŸè¨˜äº‹ã®UUID:" >> $GITHUB_STEP_SUMMARY
          jq -r '.posts[] | "- \(.title): \(.uuid)"' scripts/logs/medium_import_summary.json >> $GITHUB_STEP_SUMMARY

      - name: No new posts message
        if: steps.check_posts.outputs.has_new_posts == 'false'
        run: |
          echo "## ðŸ“ Mediumè¨˜äº‹ãƒã‚§ãƒƒã‚¯å®Œäº†" >> $GITHUB_STEP_SUMMARY
          echo "æ–°ã—ã„è¨˜äº‹ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚" >> $GITHUB_STEP_SUMMARY
